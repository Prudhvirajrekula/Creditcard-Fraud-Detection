{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "bd1ea872",
   "metadata": {},
   "source": [
    "# Credit Card Fraud Detection Project â€“ Full Notebook\n",
    "This notebook covers loading, preprocessing, model training (Logistic Regression, Decision Tree, Random Forest, XGBoost, HistGradientBoosting), evaluation, and next-step snippets for hyperparameter tuning, threshold selection, and deployment."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "39e6e509",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Optional: install/upgrade xgboost\n",
    "# !pip install --upgrade xgboost --quiet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d75407a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "from imblearn.over_sampling import SMOTE\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier, HistGradientBoostingClassifier\n",
    "from xgboost import XGBClassifier\n",
    "from sklearn.metrics import classification_report, roc_auc_score\n",
    "print('Imports loaded')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1d598389",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('creditcard.csv')\n",
    "print('Data shape:', df.shape)\n",
    "print(df['Class'].value_counts(normalize=True))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "04fe1fcd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Preprocess: check missing, scale Amount, drop Time\n",
    "assert df.isnull().sum().sum() == 0, 'Missing values!'\n",
    "scaler = StandardScaler()\n",
    "df['Amount'] = scaler.fit_transform(df[['Amount']])\n",
    "df.drop(columns=['Time'], inplace=True)\n",
    "print('Preprocessing done')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a04d02e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = df.drop(columns=['Class'])\n",
    "y = df['Class']\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y, test_size=0.2, stratify=y, random_state=42\n",
    ")\n",
    "print('Train:', X_train.shape, 'Test:', X_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9332dd24",
   "metadata": {},
   "outputs": [],
   "source": [
    "smote = SMOTE(random_state=42)\n",
    "X_train_res, y_train_res = smote.fit_resample(X_train, y_train)\n",
    "print('Resampled train:', X_train_res.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ab4fa8bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "models = {\n",
    "    'Logistic Regression': LogisticRegression(class_weight='balanced', max_iter=500, n_jobs=-1, random_state=42),\n",
    "    'Decision Tree': DecisionTreeClassifier(class_weight='balanced', random_state=42),\n",
    "    'Random Forest': RandomForestClassifier(n_estimators=50, class_weight='balanced', n_jobs=-1, random_state=42),\n",
    "    'XGBoost': XGBClassifier(n_estimators=100, scale_pos_weight=(len(y_train)-sum(y_train))/sum(y_train), n_jobs=-1, use_label_encoder=False, eval_metric='auc', random_state=42),\n",
    "    'HistGradientBoosting': HistGradientBoostingClassifier(max_iter=100, early_stopping=True, random_state=42)\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e5a0e695",
   "metadata": {},
   "outputs": [],
   "source": [
    "results = {}\n",
    "for name, model in models.items():\n",
    "    print(f\"\\n=== Training {name} ===\")\n",
    "    model.fit(X_train_res, y_train_res)\n",
    "    preds = model.predict(X_test)\n",
    "    proba = model.predict_proba(X_test)[:, 1]\n",
    "    report = classification_report(y_test, preds, output_dict=True)\n",
    "    auc = roc_auc_score(y_test, proba)\n",
    "    results[name] = {\n",
    "        'precision_fraud': report['1']['precision'],\n",
    "        'recall_fraud': report['1']['recall'],\n",
    "        'f1_fraud': report['1']['f1-score'],\n",
    "        'roc_auc': auc\n",
    "    }\n",
    "    print(f\"{name} ROC AUC: {auc:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f88dedf3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "summary_df = pd.DataFrame(results).T\n",
    "print('\\n=== Model Comparison ===')\n",
    "print(summary_df.sort_values('roc_auc', ascending=False))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ca7d6b78",
   "metadata": {},
   "source": [
    "## Hyperparameter Tuning Example\n",
    "Use RandomizedSearchCV to optimize your Random Forest:\n",
    "```python\n",
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "param_dist = {\n",
    "    'n_estimators': [50, 100, 200],\n",
    "    'max_depth': [None, 10, 20],\n",
    "    'min_samples_split': [2, 5, 10]\n",
    "}\n",
    "rf = RandomForestClassifier(class_weight='balanced', n_jobs=-1, random_state=42)\n",
    "search = RandomizedSearchCV(rf, param_dist, n_iter=20, cv=3, scoring='f1', n_jobs=-1)\n",
    "search.fit(X_train_res, y_train_res)\n",
    "print(search.best_params_)\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5facd53b",
   "metadata": {},
   "source": [
    "## Precision-Recall Threshold Selection\n",
    "Adjust probability cutoff:\n",
    "```python\n",
    "from sklearn.metrics import precision_recall_curve\n",
    "probs = models['Random Forest'].predict_proba(X_test)[:,1]\n",
    "prec, rec, thresh = precision_recall_curve(y_test, probs)\n",
    "# Choose threshold based on desired trade-off\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "53bf59a4",
   "metadata": {},
   "source": [
    "## Deployment with Streamlit\n",
    "```bash\n",
    "streamlit run app.py\n",
    "```\n",
    "Or wrap in Flask/FastAPI for an API endpoint."
   ]
  }
 ],
 "metadata": {},
 "nbformat": 4,
 "nbformat_minor": 5
}
